import gc
gc.collect()

import os

# Configuration de l'environnement pour PyTorch
os.environ['USE_NINJA'] = '1'
os.environ['BUILD_TEST'] = '0'
os.environ['USE_NUMA'] = '0'
os.environ['BUILD_DOCS'] = 'OFF'

# Configuration spécifique pour osx-arm64
if os.uname().machine == 'arm64' and os.uname().sysname == 'Darwin':
    os.environ['USE_SYSTEM_SLEEF'] = '1'

os.environ['BUILD_CUSTOM_PROTOBUF'] = 'OFF'
os.environ['USE_SYSTEM_PYBIND11'] = '1'
os.environ['USE_SYSTEM_EIGEN_INSTALL'] = '1'

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, LabelEncoder
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors3D
from tqdm import tqdm
from sklearn.model_selection import train_test_split

# Fonction pour générer les descripteurs 3D
def generate_3d_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is not None:
        mol = Chem.AddHs(mol)
        AllChem.EmbedMolecule(mol, randomSeed=42)
        AllChem.MMFFOptimizeMolecule(mol)
        
        descriptors = [
            Descriptors3D.Asphericity(mol),
            Descriptors3D.Eccentricity(mol),
            Descriptors3D.InertialShapeFactor(mol),
            Descriptors3D.NPR1(mol),
            Descriptors3D.NPR2(mol),
            Descriptors3D.PMI1(mol),
            Descriptors3D.PMI2(mol),
            Descriptors3D.PMI3(mol),
            Descriptors3D.RadiusOfGyration(mol),
            Descriptors3D.SpherocityIndex(mol),
        ]
        return descriptors
    return None

# Chargement et préparation des données
print("Loading data...")
train_data = pd.read_csv('/Users/johannatter/Documents/Thèse science/Prion/DeepLearning/Train_set.csv')
test_data = pd.read_csv('/Users/johannatter/Documents/Thèse science/Prion/DeepLearning/Test_set.csv')

# Génération des descripteurs 3D
print("Generating 3D descriptors for training set...")
train_descriptors = np.array([generate_3d_descriptors(s) for s in tqdm(train_data['Smiles'])])
print("Generating 3D descriptors for test set...")
test_descriptors = np.array([generate_3d_descriptors(s) for s in tqdm(test_data['Smiles'])])

# Préparation des données cibles
le = LabelEncoder()
y_train = le.fit_transform(train_data['Activity'].str.strip())
y_test = le.transform(test_data['Activity'].str.strip())

# Normalisation des descripteurs
scaler = StandardScaler()
X_train = scaler.fit_transform(train_descriptors)
X_test = scaler.transform(test_descriptors)

# Séparation des données d'entraînement en ensemble d'entraînement et de validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Création du modèle
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compilation du modèle
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Création d'une barre de progression personnalisée
class ProgressBar(tf.keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.epochs = self.params['epochs']
        self.progress_bar = tqdm(total=self.epochs, desc="Training")

    def on_epoch_end(self, epoch, logs={}):
        self.progress_bar.update(1)
        self.progress_bar.set_postfix({
            'loss': f"{logs.get('loss', 0):.4f}",
            'accuracy': f"{logs.get('accuracy', 0):.4f}",
            'val_loss': f"{logs.get('val_loss', 0):.4f}",
            'val_accuracy': f"{logs.get('val_accuracy', 0):.4f}"
        })

    def on_train_end(self, logs={}):
        self.progress_bar.close()

# Entraînement du modèle
print("Training model...")
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_val, y_val),
    callbacks=[
        ProgressBar(),
        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    ],
    verbose=0
)

# Évaluation du modèle
print("\nEvaluating model on test set...")
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy:.4f}")

# Prédictions sur l'ensemble de test
print("Making predictions on test set...")
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype(int).flatten()

# Calcul des métriques
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
accuracy = accuracy_score(y_test, y_pred_classes)
precision = precision_score(y_test, y_pred_classes)
recall = recall_score(y_test, y_pred_classes)
f1 = f1_score(y_test, y_pred_classes)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Sauvegarde du modèle
model.save('qsar_3d_model.h5')
print("Model saved as 'qsar_3d_model.h5'")
